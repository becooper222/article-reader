**(Start of Script)**

**(Introductory Music Fades In and Out)**

**Narrator:** Welcome. This is an audio presentation of the paper titled, "Using Virtual Reality to Improve Performance and User Experience in Manual Correction of MRI Segmentation Errors by Non-experts."

By Dominique Duncan, Rachael Garner, Ivan Zrantchev, Tyler Ard, Bradley Newman, Adam Saslow, Emily Wanserski, and Arthur W. Toga.

Published in the Journal of Digital Imaging in 2019.

***

### **Abstract**

**Narrator:** Before neuroimaging data can be properly analyzed, a critical step called segmentation is required. This process divides MRI scans into distinct regions. While there are many automatic tools to do this, none of them are perfectly accurate. This means that a person must manually inspect the results and correct any errors. This correction process is often tedious and very time-consuming.

This paper presents a new method for performing this task using a head-mounted virtual reality system and a new software called Virtual Brain Segmenter, or VBS. To test this new tool, 30 volunteers participated in a user study. The results show that VBS is a more efficient, intuitive, and engaging alternative to the current methods of correcting segmentation errors.

***

### **Introduction**

**Narrator:** In the world of neuroimaging, segmentation is a crucial first step. The goal is to take an MRI scan and algorithmically divide its tiny three-dimensional pixels, or voxels, into meaningful regions. This could mean separating brain tissue from non-brain tissue, distinguishing between gray and white matter, or identifying specific neural structures like the hippocampus. This process allows researchers to examine individual structures within the brain and perform volumetric analysis.

The "gold standard" for segmentation has long been manual tracing by an expert. However, this method is incredibly time-consuming to learn and perform, requires deep expertise in neuroanatomy, and can be inconsistent from one person to the next.

To address these issues, automatic segmentation software was developed to process images more quickly and consistently. One of the most popular open-source tools for this is called FreeSurfer. It creates computerized 3D models of the brain from MRI scans. FreeSurfer has been shown to have a strong correlation with manual hand-tracing, more so than other automated programs. However, it's still not perfect and often requires users to manually correct errors, slice by individual MRI slice.

***

### **Related Work and Motivations**

**Narrator:** Previous studies have analyzed the errors produced by FreeSurfer, particularly in the hippocampus—a brain region crucial for studying epilepsy and Alzheimer's Disease. Research has shown that FreeSurfer can overestimate the size of the hippocampus by a significant margin. Various computational methods have been developed to try and automatically correct these errors, with some success. However, despite these improvements, manual intervention is still necessary to ensure precision and accuracy.

This brings us to the core motivation for this study. The task of correcting segmentation errors is repetitive and unengaging. In research labs, it's often assigned to newcomers, like undergraduate researchers. The authors' own lab has invested significant resources in training students for this task, only to experience high turnover because the work is so unengaging and time-consuming.

This constant need for training puts a strain on experts. Therefore, developing a more efficient and engaging correction process could have multiple benefits. It could decrease the time required to correct each brain, improve the retention of research assistants, and potentially even attract more people—including non-experts—to help with the task.

In this study, the researchers introduce a novel tool called Virtual Brain Segmenter, or VBS. It uses virtual reality, or VR, as an innovative and user-friendly interface for correcting images. The central hypothesis is that if VR can better represent the 3D structure of MRI data than a traditional 2D computer screen, VBS may be more intuitive for users and lessen the burden of training.

***

### **The Benefits of Virtual Reality**

**Narrator:** Virtual reality has already proven to be an effective tool in many medical fields, from therapy for social anxiety to teaching human anatomy. For brain segmentation, VR offers a unique advantage. Users can literally walk through multiple slices of an MRI at once. They can reorient the image by simply turning their heads or grab the image to bring it closer. This provides a natural, immersive experience that goes far beyond what’s possible with a mouse and a 2D screen.

Instead of just scrolling and zooming, VR provides a true 360-degree view of each voxel, which simplifies the process of identifying which voxels belong to which neural structures. The depth perception and 3D context available in VR can help users detect subtle errors that are hard to spot on a flat screen. Furthermore, VR's immersive environment removes outside distractions, helping people stay focused and engaged on the task at hand.

For this study, the researchers chose a specific, common error to focus on. The FreeSurfer software consistently mislabels the optic nerve, categorizing it as brain tissue instead of nerve tissue. This particular error is relatively easy for a non-expert to see, making it an ideal starting point for training novices.

Figure 1 in the paper illustrates this clearly. It shows two 3D renderings of a brain. The brain on the left has a blue region highlighted, which is the part of the optic nerve that was incorrectly included in the segmentation. The brain on the right shows that same portion of the optic nerve successfully removed.

Similarly, Figure 2 shows two images of cerebral tissue. The left image is the result of FreeSurfer's initial segmentation, and the right shows the manually corrected version. A color scheme is used to represent different tissue types, which makes the differences much clearer to a non-expert than a standard grayscale image.

The researchers used an advanced VR system called the HTC Vive, which offers high resolution, a wide field of view, and a large tracking area, making it ideal for this kind of detailed, interactive work. The ultimate goal of the investigation was to test whether VBS is a more time-efficient and accurate correction tool than FreeSurfer, and to gauge user preference between the two systems.

***

### **The System: How VBS Works**

**Narrator:** The Virtual Brain Segmenter was developed using the Unity game engine for the HTC Vive platform.

Since MRI data is stored as a collection of voxels, the first step was to build a system that could read the standard NIfTI-1 file format used in neuroimaging. The data for a typical MRI scan is a grid of 256 by 256 by 256 voxels, which adds up to nearly 17 million data points. Rendering this much data in real-time, especially with features like transparency, is computationally expensive. So, the team had to design a visualization and interaction model that was both efficient and precise.

To achieve this, they created an interactive 3D view into the interior of the brain. Instead of showing one slice at a time, like in FreeSurfer, they created a visualization of seven layers of slices at once. The front layer is represented by a grid of cubes, each scaled down to about 60 percent of its size. This creates small gaps between the cubes, allowing the user to see through to the layers behind it. The cubes in the subsequent layers gradually increase in scale, so by the seventh layer, the view is solid. This clever design allows a user to see several 3D layers simultaneously, which is a huge improvement for editing 3D data.

Figure 3 in the paper shows the VBS interface. It depicts this multi-layered view of the brain data, represented by small cubes. A yellow mesh is overlaid on the image, which represents the boundary between the brain and cerebrospinal fluid, acting as another helpful visual guide.

Within this immersive environment, participants have several ways to navigate. They can turn their heads to change their view or physically walk around within a 15-by-15-foot area to move through the brain's interior.

Interaction is handled with two Vive controllers. One controller allows the user to scroll through the layers of the brain and move the entire volume's position. The second controller acts as a "wand," topped with a red sphere. This wand is used to mark voxels for removal. As the user moves the wand forward, the front layers of the brain fade away, allowing them to clearly see and edit the layers in the background. This entire editing process can be completed with a single, fluid motion.

***

### **The User Study and Experimental Design**

**Narrator:** To test the effectiveness of VBS, the researchers conducted an experiment with 30 participants, all over the age of 18 and with no prior experience in segmentation. This was done to eliminate any training bias and to test the system with the target audience: novices.

The experiment used a "within-subject" design, meaning every participant tried both methods for correcting segmentation errors.

The first method, called "Treatment A," used the standard FreeSurfer visualization tool, where users correct the brain volume on a 13-inch MacBook Air using a trackpad.

The second method, "Treatment B," utilized the new Virtual Brain Segmenter, or VBS, in the 3D immersive environment of the HTC Vive.

The experiment began with participants reading an introductory handout explaining the study's purpose: to manually remove the optic nerve that had been misidentified as brain tissue. After this, 15 participants were assigned to start with Treatment A, and the other 15 started with Treatment B.

For each method, participants received a five-minute demonstration and a five-minute practice period to get familiar with the software. Once the practice was over, a timed trial began. Participants were instructed to complete the corrections as quickly and accurately as possible. The trial ended when the participant said they were finished.

***

### **Results**

**Narrator:** The results of the experiment were striking.

On average, it took participants 232 seconds to complete the task using the traditional FreeSurfer method. With the new VBS tool, the average time dropped to just 164 seconds. This means participants were, on average, over a minute faster using the virtual reality system.

A statistical test, called a paired t-test, was conducted on these results. It produced a t-value of 4.15 and a p-value of 0.00026. For those unfamiliar with statistics, a p-value this low indicates that the result is highly statistically significant. In other words, the faster completion time with VBS wasn't just due to chance.

Figure 4 in the paper provides a visual summary of these time trials. It's a scatter plot where each dot represents one participant. The horizontal axis shows their time using VBS, and the vertical axis shows their time using FreeSurfer. A diagonal line runs across the graph. Any dot below this line means the participant was faster with VBS. The vast majority of the dots are well below this line, clearly showing the speed advantage of the VR tool.

In terms of accuracy, participants using VBS achieved a mean precision of 85% and a mean sensitivity of 86%. To put this in perspective, a previous study showed that non-experts using FreeSurfer correct errors with a mean sensitivity of 82% and a precision of only 42%. These results suggest that non-experts using VBS can perform these corrections with not only higher sensitivity but also dramatically higher precision.

The researchers calculated sensitivity as True Positives divided by the sum of True Positives and False Negatives, and precision as True Positives divided by the sum of True Positives and False Positives.

After the trials, participants filled out a survey. The feedback was overwhelmingly positive for the new system. Of the 28 participants who completed the survey, every single one said they preferred correcting the images using VBS. Many noted that the novelty of the VR experience made it more exciting and fun, with some saying it felt more like a game. Ten participants specifically stated that VBS was more intuitive or easier to use, supporting the hypothesis that a 3D environment is better suited for analyzing 3D structures like the brain.

Participants also offered suggestions for improvement. For FreeSurfer, some wished they could have used a different input device, like a touchscreen or a stylus. For VBS, suggestions included "gamifying" the experience with sound effects and a scoreboard, making some minor control adjustments, and adding an "undo" option for single voxel deletions. A few participants also mentioned that they wished they'd had more than five minutes to practice in the VR environment.

***

### **Discussion**

**Narrator:** This study successfully demonstrates that using virtual reality is a feasible and highly effective way to correct errors from automated brain segmentation. The results were obtained during participants' very first attempt, suggesting that with a little more practice, the speed and accuracy could improve even further.

From a usability standpoint, the HTC Vive's ability to let users physically walk around the virtual space is a key advantage. It promotes an active, standing posture, which can be beneficial during long work sessions, potentially reducing back and neck pain.

The fact that so many participants preferred VBS for its entertainment value is also significant. It indicates that VBS could be a much more engaging method for this type of work. This could have positive real-world implications, making it easier to recruit and retain people for the often tedious task of data correction.

This idea connects to a broader trend of using "crowdsourcing" and "gamification" for scientific research. Popular games like FoldIt, for protein structure prediction, and EyeWire, for mapping neurons, have shown that complex scientific tasks can be successfully completed by a large community of non-expert players. One recent study even explored using a crowdsourcing platform to have non-experts detect errors on MRI cortical surfaces.

The authors of this paper hope that their study is the first step toward creating a gamified VR program that can be used by a large crowd to correct segmentation errors.

Accurate segmentation is not just an academic exercise; it has far-reaching benefits in neuroscience. For example, the atrophy of the hippocampus is an early biomarker for diseases like Alzheimer's and dementia. Accurate volumetric analysis could support earlier diagnosis and intervention. Similarly, accurate segmentation of brain tumors could improve diagnostics and treatment planning.

***

### **Future Work**

**Narrator:** The next phase of this project will focus on improving the VBS software based on the valuable feedback from the user study. This includes making minor adjustments to the controls, adding a more refined "undo" feature, and adjusting the size of the editing "brush."

The team also plans to include a training phase where users receive active feedback on their accuracy. This could serve as a quality assurance check and help non-experts become more familiar with the task.

Once these features are implemented, the researchers intend to fully gamify the program by adding sound effects and a score-keeping system. The long-term vision is to transform the interface into a more visually engaging environment that is more familiar to non-experts than the inside of a brain.

Ultimately, the goal is to share the software publicly and use a crowdsourcing platform to allow users from all over the world to help correct segmentation errors. With a very large dataset of manual corrections from the crowd, it would be possible to train machine learning techniques to make the automated segmentation processes themselves even better.

**(Outro Music Fades In)**

**Narrator:** This concludes the audio presentation of "Using Virtual Reality to Improve Performance and User Experience in Manual Correction of MRI Segmentation Errors by Non-experts." Thank you for listening.

**(Outro Music Fades Out)**

**(End of Script)**
